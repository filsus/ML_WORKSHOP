{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook replicates the ResNet [paper](https://arxiv.org/abs/1512.03385) on FashionMNIST dataset, using PyTorch torchvision model. \n",
    "The torchvision model is reused by splitting the ResNet into a feature extractor and a classifier. And the training is conducted with/without the pre-trained model.\n",
    "\n",
    "The details of the implementation can be found in the notebook.\\\n",
    "More information about Resnet can be found in:\n",
    "1. [Explanation of ResNet](https://debuggercafe.com/residual-neural-networks-resnets-paper-explanation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convlution 1\n",
    "The first step on the ResNet before entering the common layer behavior is a block — called here Conv1 — consisting on a convolution + batch normalization + max pooling operation.\n",
    "\n",
    "So, first there is a convolution operation. In Figure we can see that they use a kernel size of 7, and a feature map size of 64. You need to infer that they have padded with zeros 3 times on each dimension — and check it on the PyTorch documentation. Taken this into account, it can be seen in Figure 4 that the output size of that operation will be a (112x122) volume. Since each convolution filter (of the 64) is providing one channel in the output volume, we end up with a (112x112x64) output volume — note this is free of the batch dimension to simplify the explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next step is the batch normalization, which is an element-wise operation and therefore, it does not change the size of our volume. Finally, we have the (3x3) Max Pooling operation with a stride of 2. We can also infer that they first pad the input volume, so the final volume has the desired dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv2_x => layer1 \\\n",
    "conv3_x => layer2 \\\n",
    "conv4_x => layer3 \\\n",
    "conv5_x => layer4 \\\n",
    "Each of the layers (or we can say, layer block) will contain two Basic Blocks stacked together. The following is a visualization of layer1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\ML\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import tqdm as tqdm\n",
    "from torch.autograd import Variable\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                # expand chennel from 1 to 3 to fit \n",
    "                                # ResNet pretrained model\n",
    "                                transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "                                ]) \n",
    "batch_size = 256\n",
    "\n",
    "# download dataset\n",
    "mnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "print(len(mnist_train), len(mnist_test))\n",
    "\n",
    "# Load dataset\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training without pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m start_time \u001b[39m=\u001b[39m timer()\n\u001b[0;32m     13\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m model_resnet_results \u001b[39m=\u001b[39m train(model\u001b[39m=\u001b[39;49m model_resnet,\n\u001b[0;32m     15\u001b[0m                         train_dataloader\u001b[39m=\u001b[39;49m train_loader,\n\u001b[0;32m     16\u001b[0m                         test_dataloader\u001b[39m=\u001b[39;49m test_loader,\n\u001b[0;32m     17\u001b[0m                         optimizer\u001b[39m=\u001b[39;49m optimizer,\n\u001b[0;32m     18\u001b[0m                         loss_fn\u001b[39m=\u001b[39;49m loss_fn,\n\u001b[0;32m     19\u001b[0m                         epochs\u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m \u001b[39m# End the timer and print out how long it took\u001b[39;00m\n\u001b[0;32m     21\u001b[0m end_time \u001b[39m=\u001b[39m timer()\n",
      "File \u001b[1;32me:\\BournemouthUniversity\\Assignments\\ML_FOR_MEDIA\\WORKSHOP\\TinyVGG.py:147\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m# 3. Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[1;32m--> 147\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train_step(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    148\u001b[0m                                        dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m    149\u001b[0m                                        loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[0;32m    150\u001b[0m                                        optimizer\u001b[39m=\u001b[39;49moptimizer)\n\u001b[0;32m    151\u001b[0m     test_loss, test_acc \u001b[39m=\u001b[39m test_step(model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m    152\u001b[0m         dataloader\u001b[39m=\u001b[39mtest_dataloader,\n\u001b[0;32m    153\u001b[0m         loss_fn\u001b[39m=\u001b[39mloss_fn)\n\u001b[0;32m    155\u001b[0m     \u001b[39m# 4. Print out what's happening\u001b[39;00m\n",
      "File \u001b[1;32me:\\BournemouthUniversity\\Assignments\\ML_FOR_MEDIA\\WORKSHOP\\TinyVGG.py:77\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m# 2. Calculate  and accumulate loss\u001b[39;00m\n\u001b[0;32m     76\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m---> 77\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \n\u001b[0;32m     79\u001b[0m \u001b[39m# 3. Optimizer zero grad\u001b[39;00m\n\u001b[0;32m     80\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from Resnet18_pytorch import ResNet, BasicBlock\n",
    "from TinyVGG import train\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "model_resnet = ResNet(img_channels=3, num_layers=18, block=BasicBlock, num_classes=3).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_resnet.parameters(), lr=0.001)\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model\n",
    "model_resnet_results = train(model= model_resnet,\n",
    "                        train_dataloader= train_loader,\n",
    "                        test_dataloader= test_loader,\n",
    "                        optimizer= optimizer,\n",
    "                        loss_fn= loss_fn,\n",
    "                        epochs= 20)\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using pre-trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f23ebebf80907f8b46b5d0081d10126f743c1643e8b0d4c157bef465e687b651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
